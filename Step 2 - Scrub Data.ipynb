{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas required to manipulate data into user-friendly data structure\n",
    "import pandas as pd\n",
    "\n",
    "## nltk is a leading Python library for Natural Language Processing (NLP) tasks\n",
    "import nltk\n",
    "\n",
    "## TextBlob is used for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "## stopwords is an nltk function that provides a list of commonly used, low value words (e.g. 'the', 'a' etc.)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "## Identifies specified patterns within a string \n",
    "import re\n",
    "\n",
    "## Provides list of punctuation\n",
    "import string\n",
    "\n",
    "## word_tokenize is an nltk function that splits a string into a list of words\n",
    "from nltk import word_tokenize\n",
    "\n",
    "## WordNetLemmatizer is a function that converts a word to its base form (e.g. feet to foot)\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "## Pickle allows Python objects to be saved for later use, and retrieved\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Pandas Display Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set width of pandas dataframe to ensure entire Tweet is displayed\n",
    "pd.set_option('display.max_colwidth', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data from Excel file (created in Step 1)\n",
    "df = pd.read_excel('labelled_data.xlsx', index_col=0, usecols='A:E')\n",
    "df.columns = ['network','datetime','original_tweet','subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>datetime</th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 08:05:14</td>\n",
       "      <td>@VodafoneUK Plus £2.28 package &amp;amp; posting ! ! !</td>\n",
       "      <td>Device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 08:04:05</td>\n",
       "      <td>I have repeatedly asked how to get a refund so I can use another provider. I have also asked how to escalate my complaint. @VodafoneIN refuses to give me this information. @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita</td>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 08:01:19</td>\n",
       "      <td>I have supplied visa details twice, I have been subjected to horrendously rude staff instore, and now Vodafone are stealing my money by removing services I have paid for. Tourists should not use Vodafone. @VodafoneIn @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita</td>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 07:57:42</td>\n",
       "      <td>@VodafoneIN promised yesterday I’d receive no more calls and would get an email in 30 mins. No email received. Today I received yet another call. Vodaphone incompetence means I’ll be losing the data I’ve paid for from midnight @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita</td>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 07:57:16</td>\n",
       "      <td>@VodafoneUK you send texts about rewards - this morning Lindt. It takes me to my app but they are never there. Doesn’t matter how quickly I look. It actually becomes annoying.</td>\n",
       "      <td>Promotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       network            datetime  \\\n",
       "0  @VodafoneUK 2019-12-04 08:05:14   \n",
       "1  @VodafoneUK 2019-12-04 08:04:05   \n",
       "2  @VodafoneUK 2019-12-04 08:01:19   \n",
       "3  @VodafoneUK 2019-12-04 07:57:42   \n",
       "4  @VodafoneUK 2019-12-04 07:57:16   \n",
       "\n",
       "                                                                                                                                                                                                                                                                         original_tweet  \\\n",
       "0                                                                                                                                                                                                                                    @VodafoneUK Plus £2.28 package &amp; posting ! ! !   \n",
       "1                                                         I have repeatedly asked how to get a refund so I can use another provider. I have also asked how to escalate my complaint. @VodafoneIN refuses to give me this information. @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita   \n",
       "2            I have supplied visa details twice, I have been subjected to horrendously rude staff instore, and now Vodafone are stealing my money by removing services I have paid for. Tourists should not use Vodafone. @VodafoneIn @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita   \n",
       "3  @VodafoneIN promised yesterday I’d receive no more calls and would get an email in 30 mins. No email received. Today I received yet another call. Vodaphone incompetence means I’ll be losing the data I’ve paid for from midnight @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita   \n",
       "4                                                                                                       @VodafoneUK you send texts about rewards - this morning Lindt. It takes me to my app but they are never there. Doesn’t matter how quickly I look. It actually becomes annoying.   \n",
       "\n",
       "            subject  \n",
       "0            Device  \n",
       "1  Customer Service  \n",
       "2  Customer Service  \n",
       "3  Customer Service  \n",
       "4         Promotion  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display first five rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify any missing values within the dataframe.  This will prevent further issues with data processing further down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network           0\n",
       "datetime          0\n",
       "original_tweet    1\n",
       "subject           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use isna().sum() to identify any missing values within the dataframe\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, there is only one missing value.  Since it is not possible to predict the contents of a blank tweet, this missing record will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset index to ensure sequential index\n",
    "df = df.reset_index()\n",
    "df.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop All Retweets from Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid duplicated content, all retweets will be dropped from the dataframe.  Retweets can be identified as those starting with the string \"RT\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate through each tweet.  For any tweet starting with 'RT', drop it from the dataframe\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if df['original_tweet'][i].startswith('RT'):\n",
    "        \n",
    "        df.drop(index=i, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Once all retweets have been removed, the remaining number of observations is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12562"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remaining number of tweets\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset index to ensure sequential index\n",
    "df = df.reset_index()\n",
    "df.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Subject Categories Lower Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subject will act as a target variable.  To ensure consistent labelling, the different values that this field assumes are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    0.651568\n",
       "Other               0.134851\n",
       "Customer Service    0.073714\n",
       "Network             0.043146\n",
       "Contract            0.041952\n",
       "Promotion           0.025553\n",
       "Device              0.021971\n",
       "Broadband           0.006687\n",
       "CUstomer Service    0.000318\n",
       "COntract            0.000080\n",
       "CuStomer Service    0.000080\n",
       "other               0.000080\n",
       "Name: subject, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## value_counts() identifies the different values taken on by this field\n",
    "df['subject'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, 'Other' and 'other' are considered different subjects.  So is 'COntract' and 'Contract'.  To prevent this causing issues later on, all values in this field will be made lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make all values within the subject field lower case\n",
    "df['subject'] = df['subject'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that this has worked, re-run the value_counts() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    0.651568\n",
       "other               0.134931\n",
       "customer service    0.074112\n",
       "network             0.043146\n",
       "contract            0.042032\n",
       "promotion           0.025553\n",
       "device              0.021971\n",
       "broadband           0.006687\n",
       "Name: subject, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## value_counts() identifies the different values taken on by this field\n",
    "df['subject'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use TextBlob to calculate Sentiment Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the objectives of this project is to provide an 'on-the-pulse' measure of customer satisfactions.  In order to support this aim, TextBlob can be used to calculate a sentiment score for each tweet.  The sentiment score ranges from -1 (very negative) to 0 (neutral) to 1 (very positive).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new field that indicates sentiment of a tweet using TextBlob\n",
    "df['sentiment'] = df['original_tweet'].map(lambda text: TextBlob(text).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that these sentiment scores are reasonable, 5 randomly selected positive, neutral and negative tweets are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 random reviews with the highest positive sentiment polarity: \n",
      "\n",
      "@DCass71 @ThreeUK I'm happy with Vodafone tbh!\n",
      "The VideoTech Innovation Awards are tonight and we've been nominated for our collaborative project with @@MusionEventsLtd and @VodafoneUK! Best of luck to all of the nominees! \n",
      "\n",
      "@digitaltveurope\n",
      "#VIAWARDS19 #DigitalTVAwards #LiveStreaming #5G https://t.co/8by1vtEckf\n",
      "@bradfreeman123 @ThreeUK @O2 will always be the best 👌🏻\n",
      "@threeuk fraud support 👍 Top-notch service https://t.co/BTTQWLKikK https://t.co/H3upvVngGs\n",
      "Thank you @O2 I won some tickets to #Hotboozapalooza. It was my bday on 26th Nov. It made a perfect gift. Can’t wait to go 🙌🏽\n"
     ]
    }
   ],
   "source": [
    "## Print 5 random reviews with the highest positive sentiment (1)\n",
    "print('5 random reviews with the highest positive sentiment polarity: \\n')\n",
    "positive = df.loc[df.sentiment == 1, ['original_tweet']].sample(5).values\n",
    "for tweet in positive:\n",
    "    print(tweet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 random reviews with neutral sentiment polarity: \n",
      "\n",
      "@VodafoneUK I look forward to hearing from you.\n",
      "@O2 May I add @O2 I have taken this further to the Ombudsman. So yes, thank you, I did follow your link.\n",
      "@VodafoneUK Last Christmas #verymerewards\n",
      "@O2 Oops actually it was in my junk mail 🤦🏻‍♀️\n",
      "@philsturgeon @ThreeUK @sprint Every byte counts, it sounds like\n"
     ]
    }
   ],
   "source": [
    "## Print 5 random reviews with neutral sentiment (0)\n",
    "print('5 random reviews with neutral sentiment polarity: \\n')\n",
    "neutral = df.loc[df.sentiment == 0, ['original_tweet']].sample(5).values\n",
    "for tweet in neutral:\n",
    "    print(tweet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 random reviews with the most negative sentiment polarity: \n",
      "\n",
      "@ThreeUK @ThreeUKSupport This is crazy! I have been trying since Friday morning!!!!\n",
      "@VodafoneUK is THE WORST phone provider. I called to pay my bill, it says it hasn’t gone through. I check my balance and it’s come out. It’s now in “pending” limbo. And Vodafone are saying it’s not there problem. DO NOT GET A VODAFONE CONTRACT. #Vodafone\n",
      "@O2 Just tweeting to let the rest of us know of this nasty technique. Eternal vigilance is the price of freedom.\n",
      "@ThreeUK I’ve just swapped from EE to ThreeUK and the download speeds are terrible!! I’ve gone from 65mos to 5mps!!! #DOWNLOAD #downloadspeed ##three\n",
      "@paolopescatore @VodafoneUK @VodafoneGroup Problem is 5G coverage is terrible\n"
     ]
    }
   ],
   "source": [
    "## Print 5 random reviews with the most negative sentiment (-1)\n",
    "print('5 random reviews with the most negative sentiment polarity: \\n')\n",
    "negative = df.loc[df.sentiment == -1, ['original_tweet']].sample(5).values\n",
    "for tweet in negative:\n",
    "    print(tweet[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the above, TextBlob has provided a reasonable (but not perfect) score of sentiment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create List of Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly used words, such as 'a', 'you', 'the' etc. add little value to an NLP task.  They do not help a model to distinguish between different tweets.  For this reason, it is important that they are removed.  To do this, all of these useless words (known as stopwords) must be identified.  \n",
    "\n",
    "As a starting point, NLTK provide a comprehensive list of stopwords.  This can then be augmented with punctuation, which also provides no value.  The names of the major phone networks will also be removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call the NLTK list of english stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "## Add common punctuation to this list\n",
    "stopwords_list += string.punctuation\n",
    "stopwords_list += [\"/n\",\"''\", '\"\"', '...', '``',\"'\",'’','amp']\n",
    "stopwords_list += ['vodafone', 'three','ee','o2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the stopwords list can be previewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preview the first 20 items on the stopwords list\n",
    "stopwords_list[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Tweeets: Remove Stopwords, Make Lower Case and Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pre-process each tweet, the following steps must be completed:\n",
    "\n",
    "1. Stopwords and any other low value text patterns must be removed\n",
    "2. All tweets must be made lower case (to ensure any model understands that DOG is the same word as Dog and dog)\n",
    "3. All tweets must be tokenized.  That is each string must be split into a list.\n",
    "\n",
    "To make this process most efficient, a function will be created to complete each of these tasks for a given tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to process tweet\n",
    "def process_tweet(tweet):\n",
    "    \n",
    "    ## Remove \"@username\" from each Tweet\n",
    "    pattern = '(\\w*@\\w*)'\n",
    "    p = re.compile(pattern)\n",
    "    tweet = p.sub('',tweet)\n",
    "    \n",
    "    ## Remove links from each Tweet\n",
    "    pattern2 = '((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*'\n",
    "    p = re.compile(pattern2)\n",
    "    tweet = p.sub('',tweet)\n",
    "    \n",
    "    ## Remove non-english characters\n",
    "    pattern3 = '([^\\x00-\\x7A])+'\n",
    "    p = re.compile(pattern3)\n",
    "    tweet = p.sub('',tweet)\n",
    "\n",
    "    ## Tokenize tweet\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    \n",
    "    ## Retain only words that are not in the Stopwords list\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined this function, each tweet can be processed. The processed tweets are added to an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Empty list to contain processed tweets\n",
    "tokenized_tweets = []\n",
    "\n",
    "## For loop that iterates through each tweet and processes it, before adding to the list tokenized_tweets\n",
    "for tweet in list(df['original_tweet']):\n",
    "    \n",
    "    tokenized_tweets.append(process_tweet(tweet))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the effect of processing a tweet, look at a given tweet before and after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks @VodafoneUK for an early Christmas Present. https://t.co/0cYvktGGqv'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tweet before processing\n",
    "df.loc[15]['original_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thanks', 'early', 'christmas', 'present']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tweet after processing\n",
    "tokenized_tweets[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be gauged from the above, the processed tweet retains its core meaning, without retaining any surplus-to-requirement words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next stage of preocessing, it to lemmatize tweets.  Lemmatization is the process of grouping alternative variations of a word, so that they can be interpreted as having a single meaning.  For example, goats becomes goat, and feet becomes foot.  \n",
    "\n",
    "NLTK provides a comprehensive package to assist with lemmatization called WordNetLemmatizer().  This is used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the WordNetLemmatizer() function\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an empty list to contain lemmatized words\n",
    "lemmatized_tweets = []\n",
    "\n",
    "## Iterate through each tokenized word to convert to its lemmatized form\n",
    "for tweet in tokenized_tweets:\n",
    "    \n",
    "    lemmatized = []\n",
    "    \n",
    "    for word in tweet:\n",
    "        \n",
    "        lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    lemmatized_tweets.append(lemmatized)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Tokenized/Lemmatized Tweets to Modified Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenized/lemmatized tweets can now be added to the existing dataframe.  They will be added both as tokens and as a string to ensure maximum flexibility during exploratory data analysis and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column in the existing dataframe to contain lemmatized tweets as tokens\n",
    "df['lemmatized_tweets_tokens'] = lemmatized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column in the existing dataframe to contain the lemmatized tweets as a string\n",
    "df['lemmatized_tweets_string'] = str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isobeldaley/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## For loop to make convert lemmatized/tokenized tweets back into a string\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    df['lemmatized_tweets_string'][i] = \" \".join(df.loc[i]['lemmatized_tweets_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>datetime</th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmatized_tweets_tokens</th>\n",
       "      <th>lemmatized_tweets_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 08:05:14</td>\n",
       "      <td>@VodafoneUK Plus £2.28 package &amp;amp; posting ! ! !</td>\n",
       "      <td>device</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[plus, 2.28, package, posting]</td>\n",
       "      <td>plus 2.28 package posting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 08:04:05</td>\n",
       "      <td>I have repeatedly asked how to get a refund so I can use another provider. I have also asked how to escalate my complaint. @VodafoneIN refuses to give me this information. @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita</td>\n",
       "      <td>customer service</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>[repeatedly, asked, get, refund, use, another, provider, also, asked, escalate, complaint, refuse, give, information]</td>\n",
       "      <td>repeatedly asked get refund use another provider also asked escalate complaint refuse give information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 08:01:19</td>\n",
       "      <td>I have supplied visa details twice, I have been subjected to horrendously rude staff instore, and now Vodafone are stealing my money by removing services I have paid for. Tourists should not use Vodafone. @VodafoneIn @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita</td>\n",
       "      <td>customer service</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>[supplied, visa, detail, twice, subjected, horrendously, rude, staff, instore, stealing, money, removing, service, paid, tourist, use]</td>\n",
       "      <td>supplied visa detail twice subjected horrendously rude staff instore stealing money removing service paid tourist use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 07:57:42</td>\n",
       "      <td>@VodafoneIN promised yesterday I’d receive no more calls and would get an email in 30 mins. No email received. Today I received yet another call. Vodaphone incompetence means I’ll be losing the data I’ve paid for from midnight @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita</td>\n",
       "      <td>customer service</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>[promised, yesterday, id, receive, call, would, get, email, 30, min, email, received, today, received, yet, another, call, vodaphone, incompetence, mean, ill, losing, data, ive, paid, midnight]</td>\n",
       "      <td>promised yesterday id receive call would get email 30 min email received today received yet another call vodaphone incompetence mean ill losing data ive paid midnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VodafoneUK</td>\n",
       "      <td>2019-12-04 07:57:16</td>\n",
       "      <td>@VodafoneUK you send texts about rewards - this morning Lindt. It takes me to my app but they are never there. Doesn’t matter how quickly I look. It actually becomes annoying.</td>\n",
       "      <td>promotion</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>[send, text, reward, morning, lindt, take, app, never, doesnt, matter, quickly, look, actually, becomes, annoying]</td>\n",
       "      <td>send text reward morning lindt take app never doesnt matter quickly look actually becomes annoying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       network            datetime  \\\n",
       "0  @VodafoneUK 2019-12-04 08:05:14   \n",
       "1  @VodafoneUK 2019-12-04 08:04:05   \n",
       "2  @VodafoneUK 2019-12-04 08:01:19   \n",
       "3  @VodafoneUK 2019-12-04 07:57:42   \n",
       "4  @VodafoneUK 2019-12-04 07:57:16   \n",
       "\n",
       "                                                                                                                                                                                                                                                                         original_tweet  \\\n",
       "0                                                                                                                                                                                                                                    @VodafoneUK Plus £2.28 package &amp; posting ! ! !   \n",
       "1                                                         I have repeatedly asked how to get a refund so I can use another provider. I have also asked how to escalate my complaint. @VodafoneIN refuses to give me this information. @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita   \n",
       "2            I have supplied visa details twice, I have been subjected to horrendously rude staff instore, and now Vodafone are stealing my money by removing services I have paid for. Tourists should not use Vodafone. @VodafoneIn @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita   \n",
       "3  @VodafoneIN promised yesterday I’d receive no more calls and would get an email in 30 mins. No email received. Today I received yet another call. Vodaphone incompetence means I’ll be losing the data I’ve paid for from midnight @VodafoneUK @VodafoneGroup @rmstakkar @Nairkavita   \n",
       "4                                                                                                       @VodafoneUK you send texts about rewards - this morning Lindt. It takes me to my app but they are never there. Doesn’t matter how quickly I look. It actually becomes annoying.   \n",
       "\n",
       "            subject  sentiment  \\\n",
       "0            device   0.000000   \n",
       "1  customer service  -0.300000   \n",
       "2  customer service  -0.300000   \n",
       "3  customer service  -0.250000   \n",
       "4         promotion  -0.155556   \n",
       "\n",
       "                                                                                                                                                                            lemmatized_tweets_tokens  \\\n",
       "0                                                                                                                                                                     [plus, 2.28, package, posting]   \n",
       "1                                                                              [repeatedly, asked, get, refund, use, another, provider, also, asked, escalate, complaint, refuse, give, information]   \n",
       "2                                                             [supplied, visa, detail, twice, subjected, horrendously, rude, staff, instore, stealing, money, removing, service, paid, tourist, use]   \n",
       "3  [promised, yesterday, id, receive, call, would, get, email, 30, min, email, received, today, received, yet, another, call, vodaphone, incompetence, mean, ill, losing, data, ive, paid, midnight]   \n",
       "4                                                                                 [send, text, reward, morning, lindt, take, app, never, doesnt, matter, quickly, look, actually, becomes, annoying]   \n",
       "\n",
       "                                                                                                                                                 lemmatized_tweets_string  \n",
       "0                                                                                                                                               plus 2.28 package posting  \n",
       "1                                                                  repeatedly asked get refund use another provider also asked escalate complaint refuse give information  \n",
       "2                                                   supplied visa detail twice subjected horrendously rude staff instore stealing money removing service paid tourist use  \n",
       "3  promised yesterday id receive call would get email 30 min email received today received yet another call vodaphone incompetence mean ill losing data ive paid midnight  \n",
       "4                                                                      send text reward morning lindt take app never doesnt matter quickly look actually becomes annoying  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preview the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DataFrame into Labelled and Unlabelled Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the dataframes will be split into observations with a subject label, and observations without a subject label.  These will be used as follows in a semi-supervised learning approach:\n",
    "\n",
    "- The labelled dataframe will be used to build the initial set of models\n",
    "- A set of labels will then be generated for the unlabelled dataset using this model\n",
    "- The entire dataset will then be used to rebuild the models, and identify performance improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labelled dataframe created and saved using Pickle\n",
    "df_labelled = df.loc[df['subject']!= \" \"]\n",
    "df_labelled.to_pickle('cleaned_labelled_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unabelled dataframe created and saved using Pickle\n",
    "df_unlabelled = df.loc[df['subject']== \" \"]\n",
    "df_unlabelled.to_pickle('cleaned_unlabelled_tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
